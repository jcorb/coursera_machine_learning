{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as scipy_io\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import fmin_cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_neural_net(ax, left, right, bottom, top, layer_sizes, labels=False):\n",
    "    '''\n",
    "    Draw a neural network cartoon using matplotilb.\n",
    "    \n",
    "    :usage:\n",
    "        >>> fig = plt.figure(figsize=(12, 12))\n",
    "        >>> draw_neural_net(fig.gca(), .1, .9, .1, .9, [4, 7, 2])\n",
    "    \n",
    "    :parameters:\n",
    "        - ax : matplotlib.axes.AxesSubplot\n",
    "            The axes on which to plot the cartoon (get e.g. by plt.gca())\n",
    "        - left : float\n",
    "            The center of the leftmost node(s) will be placed here\n",
    "        - right : float\n",
    "            The center of the rightmost node(s) will be placed here\n",
    "        - bottom : float\n",
    "            The center of the bottommost node(s) will be placed here\n",
    "        - top : float\n",
    "            The center of the topmost node(s) will be placed here\n",
    "        - layer_sizes : list of int\n",
    "            List of layer sizes, including input and output dimensionality\n",
    "    '''\n",
    "    n_layers = len(layer_sizes)\n",
    "    v_spacing = (top - bottom)/float(max(layer_sizes))\n",
    "    h_spacing = (right - left)/float(len(layer_sizes) - 1)\n",
    "    # Nodes\n",
    "    for n, layer_size in enumerate(layer_sizes):\n",
    "        layer_top = v_spacing*(layer_size - 1)/2. + (top + bottom)/2.\n",
    "        for m in xrange(layer_size):\n",
    "            circle = plt.Circle((n*h_spacing + left, layer_top - m*v_spacing), v_spacing/4.,\n",
    "                                color='w', ec='k', zorder=4)\n",
    "            ax.add_artist(circle)\n",
    "            if labels:\n",
    "                sub = str(m+1)\n",
    "                if n == 0:\n",
    "                    ax.text(n*h_spacing + left, layer_top - m*v_spacing, \n",
    "                            r\"$x_{:d}$\".format(m+1), \n",
    "                        ha='center', va='center', zorder=5)\n",
    "                else:\n",
    "                    sup = '('+ str(n+1) +')'                    \n",
    "                    ax.text(n*h_spacing + left, layer_top - m*v_spacing, \n",
    "                            r\"$a^{:d}_{:d}$\".format(n+1, m+1), \n",
    "                        ha='center', va='center', zorder=5)\n",
    "    # Edges\n",
    "    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "        layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.\n",
    "        layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.\n",
    "        for m in xrange(layer_size_a):\n",
    "            for o in xrange(layer_size_b):\n",
    "                line = plt.Line2D([n*h_spacing + left, (n + 1)*h_spacing + left],\n",
    "                                  [layer_top_a - m*v_spacing, layer_top_b - o*v_spacing], c='k')\n",
    "                ax.add_artist(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Neural Network\n",
    "The assignments for the Coursera Machine Learning course require you to implement a neural network using the feedfoward and backpropagation algorithms.  I didn't want to submit the assignments in matlab/octave, so I decided just to write them up in Python and post as a blog post.\n",
    "\n",
    "## The data\n",
    "The dataset was provided as part of the assignment, essentially it is a number of greyscale images of handwritten digits (0-9), along with the correct classification for that image.  The images look like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pix_file = '../assignments/machine-learning-ex4/ex4/ex4data1.mat'\n",
    "mat_in = scipy_io.loadmat(pix_file)\n",
    "X_in = mat_in['X']\n",
    "y = np.squeeze(mat_in['y'])\n",
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_in, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAEyCAYAAACF03cPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114fc4fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(5,5, figsize=(5,5))\n",
    "axs = iter(np.ravel(ax))\n",
    "for i in np.random.randint(0, 3000, 25):\n",
    "    ax = next(axs)\n",
    "    ax.imshow(X_train[i,:].reshape(20,20).T, cmap='Greys');\n",
    "    ax.set_axis_off();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The neural network\n",
    "The network I am using for this example consists of 3 layers - an input layer, an output layer, and one hidden layer.  The input layer consists of 400 input nodes (each pixel in an image, and there is actually 401 inputs when the bias, $x_0=1$, term is included).  I'm using 25 nodes (or neurons) in the hidden layer (this also gets a bias term added, $a_0^{(2)}=1$), and the output layer consists of 10 nodes - one for each of the classes.\n",
    "\n",
    "### Feed-forward\n",
    "The feed-forward calculation takes the inputs values, and applies the activation function (in this case the sigmoid) using the provided weights ($\\Theta$).  These values are then \"fed-forward\", used as the inputs to the next activation layer.  If we have a simple neural net, consisting of 3 layers with sizes 3, 3, 1 such as this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhP8PLj1e9tZ5Ve4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114fc45d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.axis('off')\n",
    "draw_neural_net(ax, .1, .9, .1, .9, [3, 3, 1], labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can calculate the values:\n",
    "\n",
    "$$\n",
    "a^2_1 = g(\\Theta^1_{10}x_0 + \\Theta^1_{11}x_1 + \\Theta^1_{12}x_2 + \\Theta^1_{13}x_3)\n",
    "$$\n",
    "$$\n",
    "a^2_2 = g(\\Theta^1_{20}x_0 + \\Theta^1_{21}x_1 + \\Theta^1_{22}x_2 + \\Theta^1_{23}x_3)\n",
    "$$\n",
    "$$\n",
    "a^2_3 = g(\\Theta^1_{30}x_0 + \\Theta^1_{31}x_1 + \\Theta^1_{32}x_2 + \\Theta^1_{33}x_3)\n",
    "$$\n",
    "and,\n",
    "$$\n",
    "a^3_1 = h_\\Theta(x) = g(\\Theta^2_{10}a^2_0 + \\Theta^2_{11}a^2_1 + \\Theta^2_{12}a^2_2 + \\Theta^2_{13}a^2_3)\n",
    "$$\n",
    "\n",
    "Where $\\Theta^l$ for $l=1,2$ are the weights mapping from layer $l$ to $l+1$ and $g(z)$ is the activation function (the sigmoid function).  This can be vectorised fairly easily. Generally, if $a^{(l)} = [a^{(l)}_0, a^{(l)}_1,..., a_{s_j}^{(l)}]$ and $z^{(l)} = [z^{(l)}_1,..., z_{s_l}^{(l)}]$, $a^{(l)} = g(z^{(l)})$, where $z^{(l)} = \\Theta^{(l-1)}a^{(l-1)}$.  This is implemented in the `feedforward()` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "def add_bias_term(a):\n",
    "    '''Inserts a 1 to the firt column of the array '''\n",
    "    m,n = a.shape\n",
    "    b = np.ones([m, n+1])\n",
    "    b[:,1:] = a\n",
    "    return b\n",
    "\n",
    "def x_to_theta(x, s_1, s_2, s_3):\n",
    "    '''Takes the vector of weights and unravels to the required array shapes'''\n",
    "    Theta1 = x[:s_2*(s_1+1)].reshape([s_2, s_1+1])\n",
    "    Theta2 = x[s_2*(s_1+1):].reshape([s_3, s_2+1])\n",
    "    return Theta1, Theta2\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1./(1. + np.exp(-1.*z))\n",
    "\n",
    "def sigmoidGradient(z):\n",
    "    return sigmoid(z) * (1. - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feedforward(X, n_layers, theta=None):\n",
    "    '''performs the feedfoward calculation in the neural net using the sigmoid activation function\n",
    "    inputs:\n",
    "        X: input variables\n",
    "        n_layers: total number of layers in the neural network\n",
    "        theta: list of length n_layers-1 containing the weights for each neuron for each \n",
    "                activation layer (1,..., n_layers)\n",
    "    returns:\n",
    "        a_out: list of length n_layers-1 containg the computed activations for each layer (1,...,n_layers)\n",
    "    '''\n",
    "    \n",
    "    a_outs = []\n",
    "    \n",
    "    #check for theta\n",
    "    if theta is not None:\n",
    "        # check theta lengths\n",
    "        if len(theta) == n_layers-1:\n",
    "            #calculate the activations for each of the layers\n",
    "            for j in range(n_layers-1):\n",
    "                # add the bias terms\n",
    "                if j==0:\n",
    "                    # activation is peformed on the input X values\n",
    "                    a = add_bias_term(X)                  \n",
    "                else:\n",
    "                    # activation is performed on the previous layers activation\n",
    "                    a = add_bias_term(a_out)\n",
    "                \n",
    "                # get the number of neurons for each layer \n",
    "                theta_j = theta[j]              \n",
    "                # calculate the activation\n",
    "                a_out = sigmoid(np.dot(a, theta_j.T)) \n",
    "                a_outs.append(a_out)\n",
    "                \n",
    "            return a_outs\n",
    "        else:\n",
    "            print 'theta list is of wrong dimension'\n",
    "            return None\n",
    "    else:\n",
    "        print 'need to provide thetas'\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back-propagation\n",
    "In order for the neural net to \"learn\" the optimal weights (or parameters, $\\Theta$) for the classification, we need to minimise the cost function over $\\Theta$.  To do this we need the cost function, $J(\\Theta)$, and its gradient, $\\frac{\\partial J(\\Theta)}{\\partial \\Theta_{ij}}$ \n",
    "#### Cost function\n",
    "\n",
    "The cost function we're using for this neural network is similar to that for the logistic regression, with the addition of a sum over the number of classes, $k$.\n",
    "$$\n",
    "J(\\theta) = \\frac{-1}{m}[\\sum^m_{i=1} \\sum^K_{k=1} [y_k^{(i)} log(h_{\\theta}(x^{(i)})_k) - (1-y_k^{(i)}) log(1 - h_{\\theta}(x^{(i)})_k)] + \\frac{\\lambda}{2m} \\sum^{L-1}_{l=1} \\sum^{S_1}_{i=1} \\sum^{S_{1+1}}_{j=1}(\\Theta_{ji}^l)^2\n",
    "$$\n",
    "\n",
    "This is implemented in the `nn_costfunction()` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# functions to use with scipy's fmin_cg\n",
    "def nn_costfunction(x, *args):\n",
    "    '''Calculates the cost function value for the neural net\n",
    "        inputs: \n",
    "            x: vector containing weights\n",
    "            args: tuple containing:\n",
    "                    y: feature vector\n",
    "                    X_f: input variables\n",
    "                    n_layers: number of layers in the neural net\n",
    "                    k: number of classes\n",
    "                    s_1: number of variables for each input\n",
    "                    s_2: number of neurons in layer 2\n",
    "                    s_3: number of neurons in layer 3\n",
    "                    lamb: lambda weigting for regularisation\n",
    "        return:\n",
    "            J_theta: value of the cost function\n",
    "            \n",
    "    TODO: make the code insensitive to the number of layers\n",
    "    '''\n",
    "    y, X_f, n_layers, k, s_1, s_2, s_3, lamb = args \n",
    "    \n",
    "    # create an [m, k] y (feature) array, where the column index \n",
    "    # corresponding to the class of that row is set to 1\n",
    "    m = y.size\n",
    "    y_exp = np.zeros([m, k])\n",
    "    y_exp[range(m),y-1] = 1\n",
    "    \n",
    "    # convert the input x vector to the theta arrays\n",
    "    Theta1, Theta2 = x_to_theta(x, s_1, s_2, s_3)\n",
    "    \n",
    "    # compute the activations using the feedfoward function\n",
    "    a_outs = feedforward(X_f, n_layers=n_layers, theta=[Theta1, Theta2])\n",
    "    \n",
    "    # the final classification is set to the last entry in a_outs\n",
    "    h_theta_x = a_outs[n_layers - 2]\n",
    "    h_theta_x[h_theta_x==1] = 0.9999 #just in case.  If these are excatly 1 the log fails     \n",
    "    \n",
    "    # calclute the cost function\n",
    "    J_theta = np.sum(-1.* y_exp * np.log(h_theta_x) - (1. - y_exp) * np.log(1. - h_theta_x))/float(m)\n",
    "\n",
    "    #include regularization\n",
    "    if lamb is not None:\n",
    "        J_theta = J_theta + (lamb/(2*m)) * (np.sum(Theta1[:,1:]**2) + np.sum(Theta2[:,1:]**2))   \n",
    "   \n",
    "    return J_theta\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Gradient\n",
    "The gradient is calculated via the method of back-propagation.  The basic idea behind this approach is that the error between the actual values and the predicted values (as determined by the cost function) is propagated back through the neural network, starting from the final layer.  The weight connecting each node (or neuron) is assigned a portion of the error, based upon the gradient of the cost function.  \n",
    "\n",
    "Starting at the final layer ($l=L=3$ in this case), we can write (via the chain-rule):\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\Theta)}{\\partial \\Theta^{(L-1)}} = \n",
    "\\frac{\\partial J(\\Theta)}{\\partial a^{(L)}} \n",
    "\\frac{\\partial a^{(L)}}{\\partial z^{(L)}} \n",
    "\\frac{\\partial z^{(L)}}{\\partial \\Theta^{(L-1)}}\n",
    "$$\n",
    "\n",
    "and for the second layer (the hidden layer, $l=2$):\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\Theta)}{\\partial \\Theta^{(L-2)}} = \n",
    "\\frac{\\partial J(\\Theta)}{\\partial a^{(L)}} \n",
    "\\frac{\\partial a^{(L)}}{\\partial z^{(L)}} \n",
    "\\frac{\\partial z^{(L)}}{\\partial a^{(L-1)}}\n",
    "\\frac{\\partial a^{(L-1)}}{\\partial z^{(L-1)}}\n",
    "\\frac{\\partial z^{(L-1)}}{\\partial \\Theta^{(L-2)}}\n",
    "$$\n",
    "\n",
    "Generally, \n",
    "\n",
    "$$\n",
    "\\frac{\\partial z^{(l)}}{\\partial \\Theta^{(l-1)}} = \\frac{\\partial (\\Theta^{(l-1)}a^{(l-1)})}{\\partial \\Theta^{(l-1)}} = a^{(l-1)}\n",
    "$$\n",
    "\n",
    "and we set\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\Theta)}{\\partial a^{(L)}} \n",
    "\\frac{\\partial a^{(L)}}{\\partial z^{(L)}}  = \\delta^{(L)}\n",
    "$$\n",
    "\n",
    "and then\n",
    "$$\n",
    "\\delta^{(L)} \n",
    "\\frac{\\partial z^{(L)}}{\\partial a^{(L-1)}}\n",
    "\\frac{\\partial a^{(L-1)}}{\\partial z^{(L-1)}} = \\delta^{(L-1)}\n",
    "$$\n",
    "\n",
    "Given that $a = g(z)$ and, $\\frac{\\partial a}{\\partial z} = a(1-a)$, $\\delta^{(L)}$ reduces (via some calculus and substitutions) to:\n",
    "$$\n",
    "\\delta^{(L)} = a^{(L)} - y        \n",
    "$$\n",
    "\n",
    "and, as \n",
    "\n",
    "$$\n",
    "\\frac{\\partial z^{(l)}}{\\partial a^{(l-1)}} = \\frac{\\partial (\\Theta^{(l-1)}a^{(l-1)})}{\\partial a^{(l-1)}} = \\Theta^{(l-1)}\n",
    "$$\n",
    "\n",
    "$\\delta^{(L-1)}$ reduces to:\n",
    "$$\n",
    "\\delta^{(L-1)} = \\delta^{(L)}\\Theta^{(L-1)} a^{(L-1)}(1-a^{(L-1)})\n",
    "$$\n",
    "\n",
    "So, putting it all together we get (for $L=3$),\n",
    "$$\n",
    "\\frac{\\partial J(\\Theta)}{\\partial \\Theta^{(2)}} = \\delta^{(3)}a^{(2)}\n",
    "$$\n",
    "and,\n",
    "$$\n",
    "\\frac{\\partial J(\\Theta)}{\\partial \\Theta^{(1)}} = \\delta^{(2)}a^{(1)}\n",
    "$$\n",
    "\n",
    "This is implemented in `nn_grad()` below.  This has not been optimised in anyway (pretty sure it can be vectorized to remove the loop), but it works and gives a good idea of what the algorithm is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_grad(x, *args):\n",
    "    '''\n",
    "    Performs the back-propagation algorithm in order to calculate the partial differntial of the\n",
    "    cost function.\n",
    "        inputs: \n",
    "            x: vector containing weights\n",
    "            args: tuple containing:\n",
    "                    y: feature vector\n",
    "                    X_f: input variables\n",
    "                    n_layers: number of layers in the neural net\n",
    "                    k: number of classes\n",
    "                    s_1: number of variables for each input\n",
    "                    s_2: number of neurons in layer 2\n",
    "                    s_3: number of neurons in layer 3\n",
    "                    lamb: lambda weigting for regularisation\n",
    "        return:\n",
    "            J_theta: value of the cost function\n",
    "            \n",
    "    TODO: make the code insensitive to the number of layers\n",
    "    '''\n",
    "    \n",
    "    y, X_f, n_layers, k, s_1, s_2, s_3, lamb = args \n",
    "    \n",
    "    # create an [m, k] y (feature) array, where the column index \n",
    "    # corresponding to the class of that row is set to 1\n",
    "    m = y.size\n",
    "    y_exp = np.zeros([m, k])\n",
    "    y_exp[range(m),y-1] = 1\n",
    "    \n",
    "    # convert the input x vector to the theta arrays\n",
    "    Theta1, Theta2 = x_to_theta(x, s_1, s_2, s_3)\n",
    "    \n",
    "    # initialise the Del arrays (used to store the accumulated cost function gradients)\n",
    "    Del_1 = np.zeros([s_2, s_1+1])\n",
    "    Del_2 = np.zeros([s_3, s_2+1])\n",
    "    \n",
    "    # loop over the input variables\n",
    "    for t in range(m):\n",
    "        \n",
    "        # this just makes the input variable a [1,s_1] vector instead of a [s_1,]\n",
    "        x_in = np.expand_dims(X_f[t,:], axis=0)\n",
    "        \n",
    "        # compute the activations\n",
    "        a_outs = feedforward(x_in, n_layers=n_layers, theta=[Theta1, Theta2])\n",
    "        a_3 = a_outs[1]\n",
    "        a_2 = add_bias_term(a_outs[0])\n",
    "        x_in = add_bias_term(x_in)\n",
    "        \n",
    "        # compute the \"error\" between the predicted values and actual values\n",
    "        delta_3 = a_3 - y_exp[t,:]\n",
    "        \n",
    "        # apportion the error due to each of the neurons in layer 2 \n",
    "        delta_2 = np.dot(delta_3, Theta2) * a_2 * (1. - a_2)\n",
    "        \n",
    "        # calculate and accumulate the gradients\n",
    "        Del_2 += np.dot(delta_3.T, a_2)\n",
    "        Del_1 += np.dot(delta_2[:,1:].T, x_in)\n",
    "    \n",
    "    Del_1 = Del_1/m\n",
    "    Del_2 = Del_2/m\n",
    "    \n",
    "    # apply regularisation\n",
    "    if lamb is not None:\n",
    "        Del_1[:,1:] =  Del_1[:,1:] + lamb/(2. * m) * Theta1[:,1:]\n",
    "        Del_2[:,1:] =  Del_2[:,1:] + lamb/(2. * m) * Theta2[:,1:]\n",
    "     \n",
    "    grad_out = np.zeros(Del_1.size + Del_2.size)\n",
    "    grad_out[:s_2*(s_1+1)] = Del_1.ravel()\n",
    "    grad_out[s_2*(s_1+1):] = Del_2.ravel()\n",
    "    \n",
    "    return grad_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the neural network\n",
    "The neural network is initialised using randomly assigned arrays for `initTheta1` and `initTheta2`, and the scipy routine `fmin_cg` is used to iterate through and minimise the cost function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.079758\n",
      "         Iterations: 400\n",
      "         Function evaluations: 1349\n",
      "         Gradient evaluations: 1349\n"
     ]
    }
   ],
   "source": [
    "#number of classes\n",
    "k = 10\n",
    "\n",
    "# input sizes\n",
    "s_1 = 400\n",
    "s_2 = 25\n",
    "s_3 = 10\n",
    "\n",
    "# set regularization\n",
    "lamb = 0.1\n",
    "\n",
    "# number of layers\n",
    "n_layers = 3\n",
    "\n",
    "#arguments that get used in the cost and grad functions \n",
    "args = (y_train, X_train, n_layers, k, s_1, s_2, s_3, lamb)\n",
    "\n",
    "# initialise the Theta arrays with some random values\n",
    "initE = 0.3\n",
    "# np.random.seed(0)\n",
    "initTheta1 = np.random.rand(s_2, s_1+1) * 2 * initE - initE\n",
    "# np.random.seed(0)\n",
    "initTheta2 = np.random.rand(s_3, s_2+1) * 2 * initE - initE\n",
    "\n",
    "#put the theta arrays into a vector\n",
    "x = np.zeros(initTheta1.size + initTheta2.size)\n",
    "x[:initTheta1.size] = initTheta1.ravel()\n",
    "x[initTheta1.size:] = initTheta2.ravel()\n",
    "\n",
    "# print nn_costfunction(x, *args)\n",
    "# print nn_grad(x, *args)\n",
    "\n",
    "# run the optimisation code\n",
    "theta_out = fmin_cg(nn_costfunction, x, fprime=nn_grad, args=args, maxiter=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimisation function returns the optimal $\\Theta$ arrays, we can then take those values and feed them through the neural network to get $h(\\Theta)_x$, our predicted classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Theta1, Theta2 = x_to_theta(theta_out, s_1, s_2, s_3)\n",
    "a_outs = feedforward(X_test, n_layers=n_layers, theta=[Theta1, Theta2])\n",
    "h_theta_x = a_outs[1]\n",
    "#find the most-likely class (maximum value in row), adds 1 because index 0 is class 1, not class 0.\n",
    "y_pred = np.argmax(h_theta_x, axis=1) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement rate 92.80%\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[101,   1,   0,   0,   3,   0,   0,   2,   0,   0],\n",
       "       [  1,  98,   0,   0,   0,   2,   1,   3,   1,   0],\n",
       "       [  0,   0,  79,   1,   1,   0,   0,   2,   0,   0],\n",
       "       [  0,   0,   0,  99,   0,   4,   0,   0,   2,   0],\n",
       "       [  0,   0,   3,   0,  92,   1,   0,   1,   1,   0],\n",
       "       [  1,   1,   0,   0,   0,  91,   0,   1,   0,   1],\n",
       "       [  1,   2,   0,   0,   0,   1,  87,   1,   4,   1],\n",
       "       [  0,   1,   0,   0,   2,   1,   3,  95,   5,   1],\n",
       "       [  1,   0,   1,   6,   0,   0,   3,   2,  92,   1],\n",
       "       [  0,   0,   0,   0,   1,   0,   0,   0,   0,  94]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Agreement rate {0:2.2f}%'.format( 100.0*np.sum(y_test==y_pred)/float(y_test.size))\n",
    "print 'Confusion matrix:'\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows we get a ~93% agreement between the predicted and actual classifications.  Its OK agreement, it might be possible to improve the agreement by increasing the number of neurons, layers, playing with the regularisation value, and running it for more iterations.  But it has been interesting building the neural network, and has given me a goodinsight into the mechanics of a basic neural network.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
